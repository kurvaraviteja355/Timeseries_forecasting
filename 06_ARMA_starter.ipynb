{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "612d5464",
   "metadata": {},
   "source": [
    "# The ARMA(p,q) model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c467c0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.arima_process import ArmaProcess\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from tqdm import tqdm_notebook\n",
    "from itertools import product\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9093312",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (9,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549b3660",
   "metadata": {},
   "source": [
    "## Simulate an ARMA(1,1) process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f8cf14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0ae8b98",
   "metadata": {},
   "source": [
    "### Test for stationarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90991a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the ADF test\n",
    "\n",
    "print(f'ADF Statistic: {ADF_result[0]}')\n",
    "print(f'p-value: {ADF_result[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd3578b",
   "metadata": {},
   "source": [
    "### Plot ACF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f57c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf(ARMA_1_1, lags=20);\n",
    "\n",
    "plt.ylim(-0.5, 1.5)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9897b530",
   "metadata": {},
   "source": [
    "## Plot PACF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d18c477",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pacf(ARMA_1_1, lags=20);\n",
    "\n",
    "plt.ylim(-0.5, 1.5)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b2d167",
   "metadata": {},
   "source": [
    "## Applying the general modeling procedure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc017f0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3e6f27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "741687d2",
   "metadata": {},
   "source": [
    "### Residuals analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab20838",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "940b0289",
   "metadata": {},
   "source": [
    "#### Q-Q plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b899cd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5dea6ef9",
   "metadata": {},
   "source": [
    "#### Ljung-Box test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae3a7fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa0aa63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41154b08",
   "metadata": {},
   "source": [
    "## Forecasting with ARMA(p,q) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed14fade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c813f5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(df['value'])\n",
    "ax.set_xlabel('Time steps')\n",
    "ax.set_ylabel('Value')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89305e3",
   "metadata": {},
   "source": [
    "### General modeling procedure\n",
    "#### Make the series stationary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1913b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the ADF test\n",
    "\n",
    "print(f'ADF Statistic: {ADF_result[0]}')\n",
    "print(f'p-value: {ADF_result[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8ad1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difference the series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e44c087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the ADF test\n",
    "\n",
    "print(f'ADF Statistic: {ADF_result[0]}')\n",
    "print(f'p-value: {ADF_result[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdff62a1",
   "metadata": {},
   "source": [
    "#### Optional: plot ACF and PACF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d2e35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf(series_diff, lags=20);\n",
    "\n",
    "plt.ylim(-0.5, 1.5)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009b94c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pacf(series_diff, lags=20);\n",
    "\n",
    "plt.ylim(-0.5, 1.5)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d381c3",
   "metadata": {},
   "source": [
    "#### Train/test split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8efcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(len(train))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956cfd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, sharex=True)\n",
    "\n",
    "ax1.plot(df['value'])\n",
    "ax1.set_xlabel('Time steps')\n",
    "ax1.set_ylabel('Value')\n",
    "ax1.axvspan(901, 1000, color='#808080', alpha=0.2)\n",
    "\n",
    "ax2.plot(df_diff['value_diff'])\n",
    "ax2.set_xlabel('Time steps')\n",
    "ax2.set_ylabel('Value')\n",
    "ax2.axvspan(899, 998, color='#808080', alpha=0.2)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe1a05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ARMA_gridsearch(endog, min_p, max_p, min_q, max_q):\n",
    "    \n",
    "    all_p = range(min_p, max_p+1, 1)\n",
    "    all_q = range(min_q, max_q+1, 1)\n",
    "    all_p_q = list(product(all_p, all_q))\n",
    "    \n",
    "    print(f'Trying {len(all_p_q)} unique models')\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for each in tqdm_notebook(all_p_q):\n",
    "        try:\n",
    "            model = SARIMAX(endog, order=(each[0], 0, each[1])).fit()\n",
    "        except:\n",
    "            continnue\n",
    "            \n",
    "        results.append([each, model.aic])\n",
    "        \n",
    "    order_df = pd.DataFrame(results)\n",
    "    order_df.columns = ['(p,q)', 'AIC']\n",
    "    \n",
    "    order_df = order_df.sort_values(by='AIC', ascending=True).reset_index(drop=True)\n",
    "    \n",
    "    return order_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaea4453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the ARMA gridsearch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3e5f37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "268fd3a2",
   "metadata": {},
   "source": [
    "#### Residuals analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9971cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d8a635",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ljung_box_test(residuals, is_seasonal, period):\n",
    "    \n",
    "    if is_seasonal:\n",
    "        lb_df = acorr_ljungbox(residuals, period=period)\n",
    "    else:\n",
    "        max_lag = min([10, len(residuals)/5])\n",
    "        \n",
    "        lb_df = acorr_ljungbox(residuals, np.arange(1, max_lag+1, 1))\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(lb_df['lb_pvalue'], 'b-', label='p-values')\n",
    "    ax.hlines(y=0.05, xmin=1, xmax=len(lb_df), color='black')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if all(pvalue > 0.05 for pvalue in lb_df['lb_pvalue']):\n",
    "        print('All values are above 0.05. We fail to reject the null hypothesis. The residuals are uncorrelated')\n",
    "    else:\n",
    "        print('One p-value is smaller than 0.05')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35ba19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Ljung-Box test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882f683b",
   "metadata": {},
   "source": [
    "#### Forecasting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7a94b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_predictions(df_diff: pd.DataFrame, last_train_value: np.array, train_len: int, horizon: int, window: int, method: str) -> list:\n",
    "    \n",
    "    TOTAL_LEN = train_len + horizon\n",
    "    \n",
    "    if method == 'mean':\n",
    "        pred_mean = []\n",
    "        \n",
    "        for i in range(train_len, TOTAL_LEN, window):\n",
    "            mean = np.mean(df_diff[:i].values)\n",
    "            pred_mean.extend(mean for _ in range(window))\n",
    "            \n",
    "        pred_mean = np.concatenate((last_train_value, pred_mean))\n",
    "        pred_mean = pred_mean.cumsum()\n",
    "        \n",
    "        return pred_mean[:100]\n",
    "\n",
    "    elif method == 'last':\n",
    "        pred_last_value = []\n",
    "        \n",
    "        for i in range(train_len, TOTAL_LEN, window):\n",
    "            last_value = df_diff[:i].iloc[-1].values[0]\n",
    "            pred_last_value.extend(last_value for _ in range(window))\n",
    "            \n",
    "        pred_last_value = np.concatenate((last_train_value, pred_last_value))\n",
    "        pred_last_value = pred_last_value.cumsum()\n",
    "        \n",
    "        return pred_last_value[:100]\n",
    "    \n",
    "    if method == 'ARMA':\n",
    "        # Get the predictions from the ARMA model\n",
    "            \n",
    "        return pred_ARMA[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedfc374",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = df[-100:].copy()\n",
    "\n",
    "TRAIN_LEN = len(train)\n",
    "HORIZON = len(test)\n",
    "LAST_TRAIN_VALUE = df.iloc[899].values\n",
    "\n",
    "windows = [1, 2, 5, 10]\n",
    "\n",
    "for window in windows:\n",
    "    pred_mean = rolling_predictions(df_diff, LAST_TRAIN_VALUE, TRAIN_LEN, HORIZON, window, 'mean')\n",
    "    pred_last = rolling_predictions(df_diff, LAST_TRAIN_VALUE, TRAIN_LEN, HORIZON, window, 'last')\n",
    "    pred_ARMA = rolling_predictions(df_diff, LAST_TRAIN_VALUE, TRAIN_LEN, HORIZON, window, 'ARMA')\n",
    "\n",
    "    pred_df[f'pred_mean_{window}'] = pred_mean\n",
    "    pred_df[f'pred_last_{window}'] = pred_last\n",
    "    pred_df[f'pred_ARMA_{window}'] = pred_ARMA\n",
    "\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ff74ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12,9))\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    \n",
    "    ax.plot(df['value'])\n",
    "    ax.plot(pred_df['value'], 'b-', label='actual')\n",
    "    ax.plot(pred_df[f'pred_mean_{windows[i]}'], 'g:', label='mean')\n",
    "    ax.plot(pred_df[f'pred_last_{windows[i]}'], 'r-.', label='last')\n",
    "    ax.plot(pred_df[f'pred_ARMA_{windows[i]}'], 'k--', label='ARMA(1,1)')\n",
    "    \n",
    "    ax.legend(loc=2)\n",
    "    ax.set_xlabel('Time steps')\n",
    "    ax.set_ylabel('Value')\n",
    "    ax.axvspan(901, 1000, color='#808080', alpha=0.2)\n",
    "    ax.set_xlim(730, 1000)\n",
    "    ax.set_title(f'Horizon = {windows[i]}')\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0e7d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_mean_1 = mean_absolute_error(pred_df['value'], pred_df['pred_mean_1'])\n",
    "mae_last_1 = mean_absolute_error(pred_df['value'], pred_df['pred_last_1'])\n",
    "mae_ARMA_1 = mean_absolute_error(pred_df['value'], pred_df['pred_ARMA_1'])\n",
    "\n",
    "mae_mean_2 = mean_absolute_error(pred_df['value'], pred_df['pred_mean_2'])\n",
    "mae_last_2 = mean_absolute_error(pred_df['value'], pred_df['pred_last_2'])\n",
    "mae_ARMA_2 = mean_absolute_error(pred_df['value'], pred_df['pred_ARMA_2'])\n",
    "\n",
    "mae_mean_5 = mean_absolute_error(pred_df['value'], pred_df['pred_mean_5'])\n",
    "mae_last_5 = mean_absolute_error(pred_df['value'], pred_df['pred_last_5'])\n",
    "mae_ARMA_5 = mean_absolute_error(pred_df['value'], pred_df['pred_ARMA_5'])\n",
    "\n",
    "mae_mean_10 = mean_absolute_error(pred_df['value'], pred_df['pred_mean_10'])\n",
    "mae_last_10 = mean_absolute_error(pred_df['value'], pred_df['pred_last_10'])\n",
    "mae_ARMA_10 = mean_absolute_error(pred_df['value'], pred_df['pred_ARMA_10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c91a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "maes_mean = [mae_mean_1, mae_mean_2, mae_mean_5, mae_mean_10]\n",
    "maes_last = [mae_last_1, mae_last_2, mae_last_5, mae_last_10]\n",
    "maes_ARMA = [mae_ARMA_1, mae_ARMA_2, mae_ARMA_5, mae_ARMA_10]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12,9))\n",
    "\n",
    "x = ['mean', 'last', 'ARMA(1,1)']\n",
    "width = 0.3\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    \n",
    "    y = [maes_mean[i], maes_last[i], maes_ARMA[i]]\n",
    "    ax.bar(x, y, width)\n",
    "    ax.set_xlabel('Methods')\n",
    "    ax.set_ylabel('MAE')\n",
    "    ax.set_ylim(0, 20)\n",
    "    ax.set_title(f'Horizon = {windows[i]}')    \n",
    "    \n",
    "    for index, value in enumerate(y):\n",
    "        ax.text(x=index, y=value+1, s=str(round(value, 2)), ha='center')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abcc23a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
